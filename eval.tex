We extensively compare the \sys\/ prototype to RocksDB -- a mature industry-leading KV-store implementation  -- under a variety of scenarios. \remove{RocksDB is used as storage layer of multiple popular SQL and NoSQL databases, e.g., MyRocks~\cite{MyRocks} (incarnation of MySQL) and MongoRocks~\cite{MongoRocks} (incarnation of MongoDB). RocksDB is an LSM-tree that is highly optimized for both read and write scenarios. For example, its compaction scheduling policies are highly tuned to minimize impact on mainstream data access.} We use the most recent RocksDB release 5.17.2, available Oct 24, 2018.  
It is worth noting that RocksDB's performance improved extensively during the last two years, primarily through 
optimized LSM compaction scheduling~\cite{RocksDBProgress}.   

\subsection{Setup}

\paragraph{Testbed.} We employ a C++ implementation~\cite{Cpp-YCSB} of a widely popular 
YCSB~\cite{Cooper:2010:BCS:1807128.1807152} benchmarking platform. 
YCSB provides a framework for KV-store comparisons, through a set of common data access API's and standard workloads. 
Most modern KV-stores implement  YCSB adapter API's. The platform decouples data access from workload generation, 
thereby providing common ground for backend comparison. 

A workload is defined by a combination of get, put, and scan accesses, as well as by a synthetic distribution of keys and values. 
YCSB provides a set of benchmark workloads inspired by real-life applications, and allows developing new ones through workload generation API's. 
A typical YCSB instance stress-tests the backend KV-store through a pool of concurrent worker threads that drive identical
workloads. It aggregates the key performance metrics for the scenario under test, e.g., total throughput and tail access latencies. 

Our hardware is a 12-core Intel Xeon 5 machine with 4TB SSD disk. The driver application exercises 12 workers 
(maximum parallelism). In order to guarantee a fair memory allocation to all KV-stores, we run each experiment 
within a Linux container with 16 GB RAM. 

\paragraph{Data.} We scale the dataset size from 4 GB to 64 GB, in order to exercise multiple locality 
scenarios with respect to the available RAM. Similarly to the published RocksDB benchmarks, we use 
10-byte keys that YCSB pads with a fixed 4-byte prefix (effectively, 14-byte keys), and 800-byte values. 
The data is stored uncompressed. 

\paragraph{Workloads.} We leverage multiple workloads: 

\begin{enumerate}
\item {\em Zipf}. The key frequencies are sampled from the heavy-tailed Zipf distribution, 
following the description in~\cite{Gray:1994:QGB:191839.191886}, with $\theta = 0.8$. 
The keys themselves are sampled uniformly at random from the whole data range. Zipf exhibits 
medium temporal locality (e.g., the most popular key's frequency is approximately $0.7\%$), 
and no spatial locality. This is a standard YCSB workload that captures a multitude of use cases 
-- e.g., a web page cache distribution by URL. 

\item {\em Zipf-range}. Similar to Zipf ($\theta=0.8$), except that we sample the key's $14$ most significant bits
(MSBs) rather than the complete key. The remainder of the key sampled uniformly at random. Zipf-range exhibits
a workload of high spatial locality, e.g., message threads~\cite{Borthakur:2011:AHG:1989323.1989438}. 

\item {\em Latest}. New KV-pairs are inserted in sequential key order; the most recently inserted ones are 
the  most popular (the sampled key's position wrt from the most recent key is distributed Zipf). This is a 
standard YCSB workload of medium spatial and temporal locality that exhibits, e.g., status updates and reads. 

\end{enumerate}

The workloads exercise different mixes of puts, gets, and scans. We use standard YCSB scenarios 
(A to E) that capture write-savvy ($50\%$ puts) to read-savvy ($95\%-100\%$ gets or scans) settings. 
In order to stress the system even more on the write side, we introduce a new workload, named 
YCSB-P, comprised of $100\%$ puts. It captures a heavy-duty data load scenario (e.g., from an 
external data pipeline). 

\paragraph{Evaluation methodology.} Each experiment consists of two stages. The first stage builds 
the dataset, by filling an initially empty store with an sequence of KV-pairs, ordered by key. The second 
phase exercises the specific scenario; all worker threads follow the same access pattern. Most experiments 
perform 80 million data accesses. The experiments that run scans perform 4 to 16 million accesses, depending 
on the scan size. We run 5 experiments for each data point, and present the median metric measurement. 

\paragraph{Configuration.} 
We only present the performance metrics in asynchronous logging mode -- as synchronous logging 
is approximately 10 times slower, thereby trivializing the results of every scenario that includes puts. 

We set the \sys\/ chunk size limit to 10 MB, and the rebalance threshold factor to $0.7$ -- i.e., 
most chunks are bound by 7 MB (which translates to approximately 700 KV-pairs per chunk). 

We allocate a quota of 13.5 GB RAM (out of the 16 GB container) to the munk and row caches, 
and split it between the two at a $2:1$ ratio. The WAL size limit, which is auto-tuned by \sys\/
(Section~\ref{sec:impl}), varies from $0.5$ MB to 2 MB. 

We tune all RocksDB runtime parameters in accordance with its system performance guide~\cite{RocksDBPerf}.   

\subsection{Results -- Mainstream Scenarios}

\begin{figure*}[tb]
\centering
\begin{subfigure}{0.3\linewidth}
\includegraphics[width=\textwidth]{figs/Workload_P_line.pdf}
\caption{YCSB-P}
\label{fig:throughput:p}
\end{subfigure}
\hspace{0.2\linewidth}
\begin{subfigure}{0.3\linewidth}
\includegraphics[width=\textwidth]{figs/Workload_A_line.pdf}
\caption{YCSB-A}
\label{fig:throughput:a}
\end{subfigure}
\begin{subfigure}{0.3\linewidth}
\includegraphics[width=\textwidth]{figs/Workload_B_line.pdf}
\caption{YCSB-B}
\label{fig:throughput:b}
\end{subfigure}
\begin{subfigure}{0.3\linewidth}
\includegraphics[width=\textwidth]{figs/Workload_C_line.pdf}
\caption{YCSB-C}
\label{fig:throughput:c}
\end{subfigure}
\begin{subfigure}{0.3\linewidth}
\includegraphics[width=\textwidth]{figs/Workload_D_line.pdf}
\caption{YCSB-D}
\label{fig:throughput:d}
\end{subfigure}
\begin{subfigure}{0.3\linewidth}
\includegraphics[width=\textwidth]{figs/Workload_E-_line.pdf}
\caption{YCSB-E10}
\label{fig:throughput:e10}
\end{subfigure}
\begin{subfigure}{0.3\linewidth}
\includegraphics[width=\textwidth]{figs/Workload_E_line.pdf}
\caption{YCSB-E100}
\label{fig:throughput:e100}
\end{subfigure}
\begin{subfigure}{0.3\linewidth}
\includegraphics[width=\textwidth]{figs/Workload_E+_line.pdf}
\caption{YCSB-E1000}
\label{fig:throughput:e1000}
\end{subfigure}
\caption{\bf{\sys\/ versus RocksDB throughput, under multiple workloads and scaling dataset sizes.}}
\label{fig:throughput}
\end{figure*}

\begin{figure*}
\centering
\hspace{0.05\linewidth}
\begin{subfigure}{0.3\linewidth}
\caption{YCSB-P}
\label{fig:writeamp:p}
\end{subfigure}
\hspace{0.05\linewidth}
\begin{subfigure}{0.25\linewidth}
\caption{YCSB-A}
\label{fig:writeamp:a}
\end{subfigure}
\caption{\bf{\sys\/ versus RocksDB write amplification, under write-intensive workloads (YCSB-P and YCSB-A) and scaling dataset sizes.}}
\label{fig:writeamp}
\end{figure*}

\begin{figure*}
\centering
\hspace{0.05\linewidth}
\begin{subfigure}{0.3\linewidth}
\caption{Disk reads}
\label{fig:readamp:d}
\end{subfigure}
\hspace{0.05\linewidth}
\begin{subfigure}{0.25\linewidth}
\caption{Kernel reads}
\label{fig:readamp:k}
\end{subfigure}
\caption{\bf{\sys\/ versus RocksDB read amplification, under the read-only workload (YCSB-C) and scaling dataset sizes.}}
\label{fig:readamp}
\end{figure*}

%\subsubsection{Throughput}
Figure~\ref{fig:throughput} summarizes the overall system throughput (operations per second) 
across all scenarios and dataset sizes. 
%Figure~\ref{fig:writeamp} presents write amplification under write-intensive workloads 
%(YCSB-P and YCSB-A). 

\paragraph{YCSB-P (100\% put, Zipf and Zipf-range distributions).} 
\sys's throughput is $30\%$ to $60\%$ above RocksDB's for Zipf-range, 
and $10\%$ to $50\%$ for Zipf (Figure~\ref{fig:throughput:p}). 
\sys\/ produces better throughput for Zipf-range compared to Zipf, 
as expected for workloads with high spatial locality. In contrast, 
RocksDB's write performance is relatively insensitive to the workload, 
which is typical for LSM data stores.

This workload's bottleneck is the persistent data reorganization 
(funk rebalances for \sys, compactions for RocksDB). The overhead
manifests in disk write rates, which \sys\/ reduces through better use of spatial locality. 
For small datasets (8 GB or less), \sys\/ accommodates all puts in munks, which alleviates 
funk rebalances altogether. For big datasets, only part of the chunks are cached, hence 
funk rebalances start occurring. However, they mostly happen to the hottest munk-less 
(torso) chunks. Hence, they incur less I/O than RocksDB's compactions, which do not 
distinguish between hot and cold data. 

Figure~\ref{fig:writeamp:p} corroborates the above observations, by comparing 
\sys's write amplification to RocksDB's. \sys\/ reduces the disk write rate dramatically, 
with the largest gain observed for big datasets (e.g., $1.29$ versus $2.92$ for the 64 GB 
database under Zipf-range). As a nice by-product, \sys\/ is also more 
efficient with respect to disk wear.  

\paragraph{YCSB-C (100\% get, Zipf and Zipf-range distributions).}  
\sys\/ achieves $1.6$x to $2.1$x throughput versus RocksDB under Zipf-range in all experiments, 
and up to $1.6$x under Zipf for small datasets (Figure~\ref{fig:throughput:c}). Similarly to YCSB-P, 
\sys's throughput is higher for Zipf-range, which exhibits higher spatial locality.  

This workload's bottleck is RAM caching efficiency -- application-level 
(munks and rows for \sys, blocks for RocksDB) and OS-level (filesystem pagecache). 
Figure~\ref{fig:readamp} compares the two systems' read amplification (as proxy 
for cache hit ratio), with respect to the number of system calls and the actual disk reads.  
In terms of disk I/O, RocksDB's metric is slightly better -- e.g., $0.94$ versus $1.07$
for the 64 GB dataset under the Zipf-range workload. However, RocksDB relies extensively 
on the filesystem cache, at the expense of the user-level block cache. In the same
setting, it performs ten times more kernel-to-user data copies than \sys.
RocksDB developers explain that the block cache scaling potential is limited in their
database, due to tension between its read-path and write-path RAM resources~\cite{RocksDB-default-blockcache-issue}. 
\sys, in contrast, exploits its munk cache for both reads and writes, which leads to better RAM utilization. 

\paragraph{YCSB-A (50\% put, 50\% get, Zipf and Zipf-range distributions).}

This scenario is particularly challenging because it stresses both the write and the read paths. 
The latter exercises \sys's munk cache as well as its row cache (which was not used by the previous 
scenario). Table~\ref{tab:hitrate} summarizes the hit rate by cache type, to explain the read performance. 

Similarly to YCSB-P, we analyze two scenarios: 

\begin{enumerate}
\item {\em Small dataset.} Both \sys\/ and RocksDB exhibit near-perfect hit ratio. RocksDB needs to search 
both its memtable and block cache, whereas \sys\/ serves all puts and gets directly from munks. Overall, it
achieves $50\%$ to $100\%$ better throughput.

\item {\em Big dataset.} \sys's read performance depends on the workload's locality. For example, 
the Zipf-range workload is highly local, and is therefore served effectively by \sys's munk cache. 
Its throughput is $30\%$ to $50\%$ higher than RocksDB's across the board. The Zipf workload
is more dispersed, and therefore, \sys\/ resorts to the row cache and I/O optimizations to serve it.  
Thanks to its fine granularity, the row cache serves a big fraction of gets that are not covered by the munks. 
For example, for the 64 GB dataset it serves $74\%$ of the gets that miss the munk cache. The rest are served 
from the disk data structures -- the key store and the WAL. TBD ... 

\end{enumerate}

The write-path behavior is similar to YCSB-P (e.g., see Figure~\ref{fig:writeamp:a} for the write
amplification statistics). 

\paragraph{YCSB-B (5\% put, 95\% get, Zipf and Zipf-prefix distributions).}


\paragraph{YCSB-D (5\% put, 95\% get, Latest distribution).}

\paragraph{YCSB-E (5\% put, 95\% scan, Zipf and Zipf-range distributions).}
We experiment with short-to-medium scans - 10, 100, and 1000 rows. 

\subsection{Results -- Recovery Scenarios}

\remove{
To drive the benchmarks, we use the 
YCSB framework in C++\footnote{}  

All three systems are configured to provided persistence, namely, no data loss, by using their synchronous logging mode.
In addition, we deploy a single partition in each of the systems in order to provide consistent scans across the entire data store.

We do not compare with Tucana~\cite{tucana} as its code has not been available; moreover, it does not support the persistency and consistency guarantees that \sys\ provides. 
}
