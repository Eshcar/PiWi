


The key requirements from \sys\ are as follows:
\begin{description}
%\item[Real-time updates] -- the system should allow updates to be processed at \inred{wire speed} with \inred{sub-millisecond} latency.  
\item[High performance with memory-resident data sets] -- we target the common 
use case where the memory size is sufficient to hold most of the active data, and strive for 
maximum performance in this case.  
 \item[Fast atomic scans] -- analytics queries ought to be able to obtain a consistent snapshot of the data store. To favor analytics queries, it is important to optimize  such scans. 
\Idit{Did we try particularly long ones or YCSB standard?}
 \item[Low write amplification] -- minimizing disk writes is important not only for performance, but also in order to reduce disk wear.
\item[Fast recovery] --  the mean-time-to-recover from crashes should be short.
\end{description} 



Given these requirements, we make the following design choices in \sys:
\paragraph{Chunk-based organization.} We employ a memory organization and caching policy based on large \emph{chunks} of data pertaining to key ranges.  This allows us to support 
long range scans efficiently, with minimal indirection and loading of new memory pages. 
Both the read and the write path go through chunks. 
Each chunk has a file representation called  \emph{funk}, and may be cached 
in-memory in a  \emph{munk} data structure.
\paragraph{Fast in-memory search and traversal.} To expedite performance when 
most of the keys are cached in munks, 
we  optimize in-memory key access. We use a number of techniques for this purpose, including partially sorting keys in each chunk and 
indexing munks.
\paragraph{Multi-versioning and CoW for atomic scans.} \sys\ employs a copy-on-write policy to keep data versions required by atomic scans.
Thus, version management incurs a low overhead (as it occurs only on scans). It also defines a simple rule for garbage collecting old versions.
%\item[Lightweight puts] -- \sys\ allows put operations to proceed quickly by `dumping' their data to the appropriate file (and possibly) memory chunk; it amortizes the cost of optimizing the chunk's organization (by sorting and compaction) across many puts.  
\paragraph{Infrequent disk compactions.} 
As long as a chunk is cached (has a munk), its funk's organization does not have to be optimized since 
queries do not access it. Therefore, \sys\ does not perform reorganization (compaction) on such funks.
Conversely, when a funk holds cold data, its organization hardly deteriorates, and therefore compaction is not necessary.
Thus, \inred{disk compactions are rare in \sys.} 
Note that this is unlike LSM-trees, where all disk components are compacted, regardless of which keys reside in memory and whether 
keys are hot or cold. 

\paragraph{In-funk WALs.} \sys\ logs writes within funks and refrains from duplicating the updates  in a separate WAL. This reduces write amplification and expedites recovery times. 
 \Idit{We could say something about parallel I/O, but I think parallel I/O hurt us in the end, no?}
\remove{
to allow updates to proceed at a high throughput, we allow different threads to perform I/O to different files simultaneously.
We thus avoid I/O bottlenecks. % as in systems that employ a single write-ahead-log.
}